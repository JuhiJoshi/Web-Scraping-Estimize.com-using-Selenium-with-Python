{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b705dac",
   "metadata": {},
   "source": [
    "## Web Scraping of Estimize.com data using Selenium with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the required libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from csv import writer\n",
    "import pandas as pd\n",
    "import time\n",
    "import csv \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a441ec",
   "metadata": {},
   "source": [
    "## List of all the tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_list = pd.read_csv('ticker_list.csv') # reading URLs of all tickers from a csv file\n",
    "ticker_list.head()\n",
    "\n",
    "ticker_url = ticker_list['URL'] # URL of the ticker\n",
    "ticker_name = ticker_list['ticker'] # Name of the ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_url.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_name.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Module for company basic information such as Ticker, Company Name, Sectors, Industries, Number of Followers, Number of Analysts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path=\"D:\\GSU\\Fall 2021\\Data Management\\chromedriver.exe\")  #Chormedriver path\n",
    "\n",
    "def get_basic_info(url,i):  # Defining a function\n",
    "\n",
    "    driver = webdriver.Chrome(executable_path=\"D:\\GSU\\Fall 2021\\Data Management\\chromedriver.exe\")\n",
    "\n",
    "    driver.get(url)\n",
    "    basic_info_list = [] #Initiating an empty list\n",
    "\n",
    "    ticker = ticker_name[i]\n",
    "    basic_info_list.append(ticker)\n",
    "    try:\n",
    "        name= driver.find_element_by_class_name('release-header-information-description').text\n",
    "        basic_info_list.append(name)\n",
    "    except NoSuchElementException:\n",
    "        basic_info_list.append('N/A')\n",
    "\n",
    "    try:    \n",
    "        sectors_industries_list = driver.find_element_by_class_name('release-header-information-breadcrumb').text.split('›')\n",
    "        sector = sectors_industries_list[0]\n",
    "        basic_info_list.append(sector)\n",
    "    except NoSuchElementException:\n",
    "        basic_info_list.append('N/A')\n",
    "\n",
    "    try:   \n",
    "        sectors_industries_list = driver.find_element_by_class_name('release-header-information-breadcrumb').text.split('›')\n",
    "        industry = sectors_industries_list[1]\n",
    "        basic_info_list.append(industry)\n",
    "    except NoSuchElementException:\n",
    "        basic_info_list.append('N/A')  \n",
    "\n",
    "    try:      \n",
    "        header = driver.find_element_by_class_name('content-header-show')\n",
    "        nav = header.find_element_by_id('summary-stats')\n",
    "        followers = nav.find_element_by_xpath('//*[@id=\"summary-stats\"]/div/div/div[1]/div[2]').text\n",
    "        basic_info_list.append(followers)\n",
    "    except NoSuchElementException:\n",
    "        basic_info_list.append('N/A')\n",
    "\n",
    "    try:\n",
    "        header = driver.find_element_by_class_name('content-header-show')\n",
    "        nav = header.find_element_by_id('summary-stats')\n",
    "        analysts = nav.find_element_by_xpath('//*[@id=\"summary-stats\"]/div/div/div[2]/a').text\n",
    "        basic_info_list.append(analysts)\n",
    "    except NoSuchElementException:\n",
    "        basic_info_list.append('N/A')\n",
    "\n",
    "\n",
    "    driver.close()\n",
    "\n",
    "    return basic_info_list\n",
    "\n",
    "for i in range(len(ticker_url)): #looping over all tickers\n",
    "        \n",
    "        # driver = webdriver.Chrome(executable_path=\"D:\\GSU\\Fall 2021\\Data Management\\chromedriver.exe\")\n",
    "    url = ticker_url[i]\n",
    "    basic_info_list = get_basic_info(url,i) #calling the function\n",
    "    \n",
    "    with open('basic_info.csv', 'a', newline=\"\", encoding='utf8') as f_object:  # saving the scraped data into a csv file\n",
    "        writer_object = writer(f_object)\n",
    "        writer_object.writerow(basic_info_list)\n",
    "\n",
    "        f_object.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting data quarter-wise for the FY 2020\n",
    "q1 = \"/fq1-2020?metric_name=eps&chart=table\"\n",
    "q2 = \"/fq2-2020?metric_name=eps&chart=table\"\n",
    "q3 = \"/fq3-2020?metric_name=eps&chart=table\"\n",
    "q4 = \"/fq4-2020?metric_name=eps&chart=table\"\n",
    "\n",
    "ticker_url_q = []\n",
    "\n",
    "for i in range(len(ticker_url)):\n",
    "    ticker_url_q.append(ticker_url[i]+q1)\n",
    "    ticker_url_q.append(ticker_url[i]+q2)\n",
    "    ticker_url_q.append(ticker_url[i]+q3)\n",
    "    ticker_url_q.append(ticker_url[i]+q4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_url_q.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Module for EPS Analysts and EPS info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eps_info(url,i): # defining a function for Reported Earnings, Estimize Consensus, Estimize Mean, Wall Street Consensus\n",
    "    driver = webdriver.Chrome(executable_path=\"D:\\GSU\\Fall 2021\\Data Management\\chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    eps_info_list = [] #initiating an empty list\n",
    "    quarter = url.split('/')[4].split('?')[0]\n",
    "    ticker = ticker_name[i] \n",
    "    eps_info_list.append(ticker)\n",
    "    eps_info_list.append(quarter)\n",
    "    try:\n",
    "        reported_earnings= driver.find_element_by_xpath('//*[@id=\"estimates\"]/table/tbody[1]/tr[1]/td[5]').text\n",
    "        eps_info_list.append(reported_earnings)\n",
    "    except NoSuchElementException:\n",
    "        eps_info_list.append('N/A')\n",
    "    \n",
    "    try:\n",
    "        estimize_concensus= driver.find_element_by_xpath('//*[@id=\"estimates\"]/table/tbody[1]/tr[2]/td[5]').text\n",
    "        eps_info_list.append(estimize_concensus)\n",
    "    except NoSuchElementException:\n",
    "        eps_info_list.append('N/A')\n",
    "    \n",
    "    try:\n",
    "        estimize_mean= driver.find_element_by_xpath('//*[@id=\"estimates\"]/table/tbody[1]/tr[3]/td[5]').text\n",
    "        eps_info_list.append(estimize_mean)\n",
    "    except NoSuchElementException:\n",
    "        eps_info_list.append('N/A')\n",
    "    \n",
    "    try:\n",
    "        ws_concensus= driver.find_element_by_xpath('//*[@id=\"estimates\"]/table/tbody[1]/tr[4]/td[5]').text\n",
    "        eps_info_list.append(ws_concensus)\n",
    "    except NoSuchElementException:\n",
    "        eps_info_list.append('N/A')\n",
    "        \n",
    "    driver.close()\n",
    "    return eps_info_list\n",
    "\n",
    "\n",
    "#get_analyst_eps_info_list('https://www.estimize.com/fsct/fq1-2020?metric_name=eps&chart=historical',1)\n",
    "i = 0  #initializing i to 0\n",
    "for j in range(len(ticker_name)): # looping over all tickers\n",
    "    lo_lim = i\n",
    "    up_lim = i+4\n",
    "    for k in range(lo_lim,up_lim):\n",
    "        url = ticker_url_q[k]\n",
    "        eps_info_list = get_eps_info(url,j) #calling the function \n",
    "    \n",
    "        with open('eps_info.csv', 'a', newline=\"\", encoding='utf8') as f_object: # saving the scraped data into a csv file\n",
    "            writer_object = writer(f_object)\n",
    "            writer_object.writerow(eps_info_list)\n",
    "\n",
    "            f_object.close()\n",
    "            if ((k+1) % 4 == 0):\n",
    "                i = up_lim\n",
    "                break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_analyst_eps_info_table(url,i): #defining the function for EPS estimations of all available analysts\n",
    "    driver = webdriver.Chrome(executable_path=\"D:\\GSU\\Fall 2021\\Data Management\\chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    \n",
    "    analyst_eps_info_table = [] # creating an empty list\n",
    "    ticker = ticker_name[i] # creating an empty list\n",
    "\n",
    "    try:\n",
    "        eps_analyst_table = driver.find_element_by_xpath('//*[@id=\"estimates\"]/table').text\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    driver.close()\n",
    "    eps_analyst_table = eps_analyst_table.split('Show Estimate')[1:]\n",
    "    return eps_analyst_table\n",
    "\n",
    "i = 0 \n",
    "analyst_eps_table = pd.DataFrame(columns=['ticker','quarter','username','name','rank','points','estimate','confidence','last_revised'])\n",
    "for j in range(len(ticker_name)): #looping over all tickers\n",
    "    lo_lim = i\n",
    "    up_lim = i+4\n",
    "    for k in range(lo_lim,up_lim):\n",
    "        url = ticker_url_q[k]\n",
    "        analyst_eps_info_list = get_analyst_eps_info_table(url,j)\n",
    "        if not analyst_eps_info_list:\n",
    "            analyst_eps_table.loc[len(analyst_eps_table),:] = [ticker_name[j],url.split('/')[4].split('?')[0],'N/A','N/A','N/A','N/A','N/A','N/A','N/A']\n",
    "            if ((k+1) % 4 == 0):\n",
    "                i = up_lim\n",
    "                break;\n",
    "        else:\n",
    "            for m in range(len(analyst_eps_info_list)):\n",
    "                final_list = []\n",
    "                quarter = url.split('/')[4].split('?')[0]\n",
    "                ticker = ticker_name[j]\n",
    "                final_list.append(ticker)\n",
    "                final_list.append(quarter)\n",
    "\n",
    "                try:\n",
    "                    eps_analyst_username = analyst_eps_info_list[m].split('\\n')[3]\n",
    "                    final_list.append(eps_analyst_username)\n",
    "                except:\n",
    "                    final_list.append('N/A')\n",
    "\n",
    "                try:\n",
    "                    eps_analyst_name = analyst_eps_info_list[m].split('\\n')[2]\n",
    "                    final_list.append(eps_analyst_name)\n",
    "                except:\n",
    "                    final_list.append('N/A')\n",
    "\n",
    "                try:\n",
    "                    eps_analyst_rank = int(analyst_eps_info_list[m].split('\\n')[4].split(' ')[0])\n",
    "                    final_list.append(eps_analyst_rank)\n",
    "                except:\n",
    "                    final_list.append('N/A')\n",
    "\n",
    "                try:\n",
    "                    eps_analyst_points = int(analyst_eps_info_list[m].split('\\n')[4].split(' ')[1])\n",
    "                    final_list.append(eps_analyst_points)\n",
    "                except:\n",
    "                    final_list.append('N/A')\n",
    "\n",
    "                try:\n",
    "                    eps_analyst_estimate = float(analyst_eps_info_list[m].split('\\n')[4].split(' ')[2])\n",
    "                    final_list.append(eps_analyst_estimate)\n",
    "                except:\n",
    "                    final_list.append('N/A')\n",
    "\n",
    "                try:\n",
    "                    eps_analyst_confidence = analyst_eps_info_list[m].split('\\n')[5].split(' ')[0]\n",
    "                    final_list.append(eps_analyst_confidence)\n",
    "                except:\n",
    "                    final_list.append('N/A')\n",
    "\n",
    "                try:\n",
    "                    eps_analyst_revised = analyst_eps_info_list[m].split('\\n')[5].split(' ')[1]\n",
    "                    final_list.append(eps_analyst_revised)\n",
    "                except:\n",
    "                    final_list.append('N/A')\n",
    "\n",
    "                analyst_eps_table.loc[len(analyst_eps_table),:] = final_list\n",
    "                    \n",
    "                if ((k+1) % 4 == 0):\n",
    "                    i = up_lim\n",
    "                    break; \n",
    "\n",
    "#Exporting dataframe to CSV\n",
    "analyst_eps_table.to_csv('analyst_eps_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyst_eps_table = pd.read_csv('analyst_eps_table.csv')\n",
    "analyst_eps_table['username'] = analyst_eps_table['username'].astype(str).dropna()\n",
    "analyst_username = analyst_eps_table['username'].unique().tolist()\n",
    "analyst_username = list(map(lambda x: x.lower(), analyst_username))\n",
    "link_prefix = \"https://www.estimize.com/users/\"\n",
    "\n",
    "analyst_url = []\n",
    "\n",
    "for i in range(len(analyst_username)):\n",
    "    analyst_url.append(link_prefix+analyst_username[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyst_username = analyst_username[1:]\n",
    "analyst_url = analyst_url[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyst_url.remove('https://www.estimize.com/users/nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyst_username.remove('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b1d26a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyst_username = pd.read_csv('D:\\GSU\\Fall 2021\\Data Management\\AnalystsUsername.csv') #Getting analyst username\n",
    "\n",
    "analyst_url = pd.read_csv('D:\\GSU\\Fall 2021\\Data Management\\AnalystsURL.csv') #Getting analyst URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79e48d1",
   "metadata": {},
   "source": [
    "## Third Module for getting details of all analysts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_analyst_info(url,i):\n",
    "    driver = webdriver.Chrome(executable_path='D:\\GSU\\Fall 2021\\Data Management\\chromedriver')\n",
    "    #driver.set_page_load_timeout(30)\n",
    "    driver.get(url)\n",
    "    #unhash the following two lines if the page takes long time to load\n",
    "    #delay=30\n",
    "    #element_loc = WebDriverWait(driver, delay).until(EC.presence_of_element_located((By.ID ,'profile-covered-stocks')))\n",
    "    analyst_user = analyst_username[i]\n",
    "    analyst_info_list = []\n",
    "    analyst_info_list.append(analyst_user)\n",
    "    #/html/body/div[4]/div[2]/div/div[2]/div[2]/div[3]/div[4]/table\n",
    "\n",
    "    try: \n",
    "        analyst_name = driver.find_element_by_class_name('profile-display-name').text\n",
    "        analyst_info_list.append(analyst_name)\n",
    "    except NoSuchElementException:\n",
    "        analyst_info_list.append('N/A')\n",
    "\n",
    "    try:\n",
    "        analyst_role = driver.find_element_by_class_name('profile-bio-categorizations').text\n",
    "        analyst_info_list.append(analyst_role)\n",
    "    except NoSuchElementException:\n",
    "        analyst_info_list.append('N/A')\n",
    "\n",
    "    try:\n",
    "        analyst_join_date = driver.find_element_by_class_name('profile-activity-stats').text.split('since ')[1]\n",
    "        if '-' in analyst_join_date:\n",
    "            analyst_info_list.append(analyst_join_date.split('-')[0])\n",
    "        else:\n",
    "            analyst_info_list.append(analyst_join_date)\n",
    "    except NoSuchElementException:\n",
    "        analyst_info_list.append('N/A')\n",
    "\n",
    "    try:\n",
    "        analyst_confidence = driver.find_element_by_xpath('//*[@id=\"confidence-wrap\"]/div/div[2]').text\n",
    "        if analyst_confidence == '-' or analyst_confidence == 'N/A':\n",
    "            analyst_info_list.append('N/A')\n",
    "        else:\n",
    "            analyst_info_list.append(float(analyst_confidence))\n",
    "    except NoSuchElementException:\n",
    "        analyst_info_list.append('N/A')\n",
    "\n",
    "    try:\n",
    "        analyst_error = driver.find_element_by_xpath('//*[@id=\"profile-tab-wrap\"]/div[1]/div[1]/div[1]').text\n",
    "        if analyst_error == '-' or analyst_error == 'N/A':\n",
    "            analyst_info_list.append('N/A')\n",
    "        else:\n",
    "            analyst_info_list.append(analyst_error)\n",
    "    except NoSuchElementException:\n",
    "        analyst_info_list.append('N/A')\n",
    "\n",
    "    try:\n",
    "        analyst_accuracy = driver.find_element_by_xpath('//*[@id=\"profile-tab-wrap\"]/div[1]/div[2]/div[1]').text\n",
    "        analyst_info_list.append(analyst_accuracy)\n",
    "    except NoSuchElementException:\n",
    "        analyst_info_list.append('N/A')\n",
    "\n",
    "    try:\n",
    "        analyst_points = driver.find_element_by_xpath('//*[@id=\"profile-tab-wrap\"]/div[2]/div[1]/div[1]').text.replace(\",\", \"\")\n",
    "        if analyst_points == '-':\n",
    "            analyst_info_list.append('N/A')\n",
    "        else:\n",
    "            analyst_info_list.append(float(analyst_points))\n",
    "    except NoSuchElementException:\n",
    "        analyst_info_list.append('N/A')\n",
    "\n",
    "\n",
    "    try:\n",
    "        analyst_points_estimate = driver.find_element_by_xpath('//*[@id=\"profile-tab-wrap\"]/div[2]/div[2]/div[1]').text.replace(\",\", \"\")\n",
    "        if analyst_points_estimate == '-':\n",
    "            analyst_info_list.append('N/A')\n",
    "        else:\n",
    "            analyst_info_list.append(float(analyst_points_estimate))\n",
    "    except NoSuchElementException:\n",
    "        analyst_info_list.append('N/A')\n",
    "\n",
    "    try:\n",
    "        analyst_stocks = driver.find_element_by_xpath('//*[@id=\"profile-tab-wrap\"]/div[3]/div[1]/div[1]').text.replace(\",\", \"\")\n",
    "        if analyst_stocks == '-':\n",
    "            analyst_info_list.append('N/A')\n",
    "        else:\n",
    "            analyst_info_list.append(float(analyst_stocks))\n",
    "    except NoSuchElementException:\n",
    "        analyst_info_list.append('N/A')\n",
    "\n",
    "    try:\n",
    "        analyst_pen_est = driver.find_element_by_xpath('//*[@id=\"profile-tab-wrap\"]/div[3]/div[2]/div[1]').text.replace(\",\", \"\")\n",
    "        if analyst_pen_est == '-':\n",
    "            analyst_info_list.append('N/A')\n",
    "        else:\n",
    "            analyst_info_list.append(float(analyst_pen_est))\n",
    "    except NoSuchElementException:\n",
    "        analyst_info_list.append('N/A')\n",
    "\n",
    "    driver.close()\n",
    "    return analyst_info_list\n",
    "\n",
    "analyst_info_table = pd.DataFrame(columns=['Username','Name','Role','Join Date','Analyst Confidence Score','Error Rate','Accuracy Percentile','Points','Points/Estimate','Stocks','Pending'])\n",
    "\n",
    "for i in range(len(analyst_url)):\n",
    "    url=analyst_url[i]\n",
    "    analyst_information = get_analyst_info(url,i)\n",
    "    analyst_info_table.loc[len(analyst_info_table),:] = analyst_information\n",
    "    \n",
    "#Exporting dataframe to csv\n",
    "#analyst_info_table.to_csv('analyst_info_table.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f771122",
   "metadata": {},
   "source": [
    "## Fourth Modeule for all covered stock estimates by the analyst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f49aea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "browser1 = webdriver.Chrome(executable_path=r'D:\\GSU\\Fall 2021\\Data Management\\chromedriver')\n",
    "analyst_list = pd.read_csv('unique_usernames.csv').username.tolist()\n",
    "\n",
    "analysts = []\n",
    "tickers = []\n",
    "reports = []\n",
    "quarters = []\n",
    "points = []\n",
    "pt_sts = []\n",
    "err_rates = []\n",
    "accuracies = []\n",
    "\n",
    "print(len(analyst_list))\n",
    "num = 0\n",
    "\n",
    "for analyst in analyst_list:\n",
    "    num = num+1\n",
    "    print(num)\n",
    "    url = 'https://www.estimize.com/users/'+analyst\n",
    "    browser1.get(url)\n",
    "    \n",
    "    browser1.execute_script(\"window.scrollTo(0, window.scrollY + 1200)\") #scrolling to a particular height\n",
    "    time.sleep(2)\n",
    "    \n",
    "    for a in range(0,1): #if there are no element in the stocks covered table.\n",
    "        a = a+1\n",
    "        try:\n",
    "            #print(\"checking the show more button\")\n",
    "            if(browser1.find_element(By.XPATH,'//*[@id=\"profile-covered-stocks\"]/div[2]/a')):\n",
    "                #print(\"in here 1\") //*[@id=\"profile-covered-stocks\"]/div[1]/div[2]/div[1]/div[3]\n",
    "                a = browser1.find_element(By.XPATH,'//*[@id=\"profile-covered-stocks\"]/div[2]/a')\n",
    "                #print(a)\n",
    "                a.click()\n",
    "\n",
    "        except NoSuchElementException: \n",
    "            break\n",
    "        \n",
    "    \n",
    "    for j in range(1,31):\n",
    "        \n",
    "        for a in range(0,1): #if there are no element in the stocks covered table.\n",
    "                a = a+1\n",
    "                try:\n",
    "                    if(browser1.find_element(By.XPATH,'//*[@id=\"profile-scored-estimates\"]/div[1]/div[2]/a['+str(j)+']/div[1]')):\n",
    "                        #print(\"in here 2\")\n",
    "                        #print(j)\n",
    "                        ticker = browser1.find_element(By.XPATH,'//*[@id=\"profile-covered-stocks\"]/div[1]/div[2]/div['+str(j)+']/div[1]/a').text\n",
    "                        #print(ticker)\n",
    "                        quarter = browser1.find_element(By.XPATH,'//*[@id=\"profile-covered-stocks\"]/div[1]/div[2]/div['+str(j)+']/div[3]').text\n",
    "                        point = browser1.find_element(By.XPATH,'//*[@id=\"profile-covered-stocks\"]/div[1]/div[2]/div['+str(j)+']/div[4]').text\n",
    "                        pt_st = browser1.find_element(By.XPATH,'//*[@id=\"profile-covered-stocks\"]/div[1]/div[2]/div['+str(j)+']/div[5]').text\n",
    "                        err_rate = browser1.find_element(By.XPATH,'//*[@id=\"profile-covered-stocks\"]/div[1]/div[2]/div['+str(j)+']/div[6]').text\n",
    "                        accuray = browser1.find_element(By.XPATH,'//*[@id=\"profile-covered-stocks\"]/div[1]/div[2]/div['+str(j)+']/div[7]').text\n",
    "                        \n",
    "                        analysts.append(analyst)\n",
    "                        tickers.append(ticker)\n",
    "                        quarters.append(quarter)\n",
    "                        points.append(point)\n",
    "                        pt_sts.append(pt_st)\n",
    "                        err_rates.append(err_rate)\n",
    "                        accuracies.append(accuray)\n",
    "                        \n",
    "                except NoSuchElementException:\n",
    "                    break\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1e895ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['analyst']=analysts\n",
    "df['tickers']=tickers\n",
    "df['quarters']=quarters\n",
    "df['points']=points\n",
    "df['pt_sts']=pt_sts\n",
    "df['err_rates']=err_rates\n",
    "df['accuracies']=accuracies\n",
    "\n",
    "df.to_csv('stocks_covered.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1708159c",
   "metadata": {},
   "source": [
    "## Fifth modeule for all pending stock estimates by the analyst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92ffe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "# driver = webdriver.Chrome(executable_path=r'D:\\GSU\\Fall 2021\\Data Management\\chromedriver')\n",
    "browser1 = webdriver.Chrome(executable_path=r'D:\\GSU\\Fall 2021\\Data Management\\chromedriver')\n",
    "analyst_list = ['canaccord_146','billb1210']\n",
    "# analyst_list = pd.read_excel('df_analyst_new.xlsx').Username.tolist()\n",
    "#analyst_list = pd.read_excel('df_analyst_new_1.xlsx').Username.tolist()\n",
    "\n",
    "#analyst_list = analyst_list[0:3]\n",
    "\n",
    "analysts=[]\n",
    "tickers = []\n",
    "\n",
    "quarters = []\n",
    "epss = []\n",
    "revenues = []\n",
    "# reportss = []\n",
    "# publisheds = []\n",
    "\n",
    "print(len(analyst_list))\n",
    "num = 0\n",
    "                \n",
    "\n",
    "for analyst in analyst_list:\n",
    "    url = 'https://www.estimize.com/users/'+analyst\n",
    "    browser1.get(url)\n",
    "    \n",
    "    browser1.execute_script(\"window.scrollTo(0, window.scrollY + 1200)\") #scrolling to a particular height\n",
    "    time.sleep(3)\n",
    "    \n",
    "    for a in range(0,1): #if there are no element in the stocks covered table.\n",
    "        a = a+1\n",
    "        try:\n",
    "            print(\"checking the show more button\")\n",
    "            if(browser1.find_element(By.XPATH,'//*[@id=\"profile-pending-estimates\"]/div[2]/a[2]')):\n",
    "                print(\"in here 1\")\n",
    "                a = browser1.find_element(By.XPATH,'//*[@id=\"profile-pending-stocks\"]/div[2]/a[2]')\n",
    "                print(a)\n",
    "                a.click()\n",
    "        except NoSuchElementException:\n",
    "            break\n",
    "        \n",
    "    \n",
    "    for j in range(1,31):\n",
    "        \n",
    "        for a in range(0,1): #if there are no element in the stocks covered table.\n",
    "                a = a+1\n",
    "                try:\n",
    "                    # //*[@id=\"profile-pending-estimates\"]/div[1]/div[2]/a[1]\n",
    "                    if(browser1.find_element(By.XPATH,'//*[@id=\"profile-pending-estimates\"]/div[1]/div[2]/a['+str(j)+']/div[1]/strong')):\n",
    "                        #print(\"in here 2\")\n",
    "                        #print(j)\n",
    "                        ticker = browser1.find_element(By.XPATH,'//*[@id=\"profile-pending-estimates\"]/div[1]/div[2]/a['+str(j)+']/div[1]/strong').text\n",
    "                        #print(ticker)\n",
    "                        quarter = browser1.find_element(By.XPATH,'//*[@id=\"profile-pending-estimates\"]/div[1]/div[2]/a['+str(j)+']/div[2]').text\n",
    "                        #print(quarter)\n",
    "                        # reports = browser1.find_element(By.XPATH,'//*[@id=\"profile-pending-estimates\"]/div[1]/div[2]/a['+str(j)+']/div[3]').text\n",
    "                        # published = browser1.find_element(By.XPATH,'//*[@id=\"profile-pending-estimates\"]/div[1]/div[2]/a['+str(j)+']/div[4]').text\n",
    "\n",
    "                        eps = browser1.find_element(By.XPATH,'//*[@id=\"profile-pending-estimates\"]/div[1]/div[2]/a['+str(j)+']/div[5]').text\n",
    "                        #print(eps_point)\n",
    "                        revenue = browser1.find_element(By.XPATH,'//*[@id=\"profile-pending-estimates\"]/div[1]/div[2]/a['+str(j)+']/div[6]').text\n",
    "                        #print(revenue_point)\n",
    "                        \n",
    "                        #print(total_point)\n",
    "\n",
    "                        \n",
    "                        analysts.append(analyst)\n",
    "                        tickers.append(ticker)\n",
    "                        #reports.append(report)\n",
    "                        quarters.append(quarter)\n",
    "                        epss.append(eps)\n",
    "                        revenues.append(revenue)\n",
    "                        # reportss.append(reports)\n",
    "                        # publisheds.append(published)\n",
    "                        #err_rates.append(err_rate)\n",
    "                        #accuracies.append(accuray)\n",
    "                        \n",
    "                except NoSuchElementException:\n",
    "                    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08bf61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame()\n",
    "df2['analyst']=analysts\n",
    "df2['tickers']=tickers\n",
    "df2['quarters']=quarters\n",
    "# df2['reports'] = reports\n",
    "# df2['publisheds'] = publisheds\n",
    "df2['eps']=epss\n",
    "df2['revenue']=revenues\n",
    "\n",
    "\n",
    "# df2\n",
    "df2.to_csv('penidng_stocks.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce78d3ff",
   "metadata": {},
   "source": [
    "## Sixth module for all scored stock estimates by the analyst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "69a194e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quanttrader007</td>\n",
       "      <td>FLR</td>\n",
       "      <td>Q2 2020</td>\n",
       "      <td>11 / 22</td>\n",
       "      <td>-3</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quanttrader007</td>\n",
       "      <td>MLCO</td>\n",
       "      <td>Q2 2020</td>\n",
       "      <td>24 / 25</td>\n",
       "      <td>-4</td>\n",
       "      <td>-25</td>\n",
       "      <td>-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quanttrader007</td>\n",
       "      <td>WOLF</td>\n",
       "      <td>Q4 2020</td>\n",
       "      <td>32 / 37</td>\n",
       "      <td>-4</td>\n",
       "      <td>-6</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quanttrader007</td>\n",
       "      <td>MDP</td>\n",
       "      <td>Q4 2020</td>\n",
       "      <td>9 / 10</td>\n",
       "      <td>-6</td>\n",
       "      <td>-7</td>\n",
       "      <td>-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>quanttrader007</td>\n",
       "      <td>ICON</td>\n",
       "      <td>Q2 2020</td>\n",
       "      <td>3 / 3</td>\n",
       "      <td>-6</td>\n",
       "      <td>-4</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3052</th>\n",
       "      <td>analyst_1729238</td>\n",
       "      <td>TAP</td>\n",
       "      <td>Q2 2021</td>\n",
       "      <td>15 / 15</td>\n",
       "      <td>-9</td>\n",
       "      <td>-25</td>\n",
       "      <td>-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3053</th>\n",
       "      <td>analyst_1729238</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Q3 2021</td>\n",
       "      <td>14 / 348</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3054</th>\n",
       "      <td>analyst_1729238</td>\n",
       "      <td>DHR</td>\n",
       "      <td>Q2 2021</td>\n",
       "      <td>10 / 11</td>\n",
       "      <td>-6</td>\n",
       "      <td>-7</td>\n",
       "      <td>-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3055</th>\n",
       "      <td>analyst_1729238</td>\n",
       "      <td>FDX</td>\n",
       "      <td>Q4 2021</td>\n",
       "      <td>25 / 27</td>\n",
       "      <td>-25</td>\n",
       "      <td>-18</td>\n",
       "      <td>-43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3056</th>\n",
       "      <td>mista</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3057 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0     1        2         3    4    5    6\n",
       "0      quanttrader007   FLR  Q2 2020   11 / 22   -3   11    8\n",
       "1      quanttrader007  MLCO  Q2 2020   24 / 25   -4  -25  -29\n",
       "2      quanttrader007  WOLF  Q4 2020   32 / 37   -4   -6  -10\n",
       "3      quanttrader007   MDP  Q4 2020    9 / 10   -6   -7  -13\n",
       "4      quanttrader007  ICON  Q2 2020     3 / 3   -6   -4  -10\n",
       "...               ...   ...      ...       ...  ...  ...  ...\n",
       "3052  analyst_1729238   TAP  Q2 2021   15 / 15   -9  -25  -34\n",
       "3053  analyst_1729238  AAPL  Q3 2021  14 / 348   19   24   43\n",
       "3054  analyst_1729238   DHR  Q2 2021   10 / 11   -6   -7  -13\n",
       "3055  analyst_1729238   FDX  Q4 2021   25 / 27  -25  -18  -43\n",
       "3056            mista                                        \n",
       "\n",
       "[3057 rows x 7 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "time.sleep(0.5)\n",
    "scored_list = []\n",
    "# loop through each analyst page\n",
    "browser = webdriver.Chrome(executable_path=r'D:\\GSU\\Fall 2021\\Data Management\\chromedriver')\n",
    "analyst_list_2 = pd.read_csv('unique_usernames.csv').username.tolist()\n",
    "for i in range(0,len(analyst_list_2)):\n",
    "\n",
    "    url = 'https://www.estimize.com/users/' + analyst_list_2[i]\n",
    "    browser.get(url)\n",
    "    # count total scored estimate    \n",
    "    try:\n",
    "        count = int(browser.find_element(By.XPATH,'//*[@id=\"equities\"]/div[1]/div[4]/p/strong/span[2]').text)\n",
    "    except:\n",
    "        count = 0\n",
    "            \n",
    "    if count == 0:\n",
    "        insert_row = []\n",
    "        insert_row.extend([analyst_list_2[i],'', '', '', '', '', '' ])\n",
    "        scored_list.append(insert_row)\n",
    "    else:\n",
    "        # click show 20 more\n",
    "        try:\n",
    "            click_list = browser.find_elements(By.XPATH, '//*[@id=\"profile-scored-estimates\"]/div[2]/a[2]')\n",
    "            click_list[0].click()\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "        try:\n",
    "            click_list = browser.find_elements(By.XPATH, '//*[@id=\"profile-scored-estimates\"]/div[2]/a[1]')\n",
    "            click_list[0].click()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            click_list = browser.find_elements(By.XPATH, '//*[@id=\"profile-scored-estimates\"]/div[2]/a')\n",
    "            click_list[0].click()\n",
    "        except:\n",
    "            pass\n",
    "        # loop through scored est. table\n",
    "        for j in range(1, min(20, count)+1):  \n",
    "            insert_row = []\n",
    "              \n",
    "            ticker = browser.find_element(By.XPATH,' //*[@id=\"profile-scored-estimates\"]/div[1]/div[2]/a['+\n",
    "                                                        str(j) + ']/div[1]/strong').text\n",
    "            Quarter = browser.find_element(By.XPATH,'//*[@id=\"profile-scored-estimates\"]/div[1]/div[2]/a[' + \n",
    "                                                        str(j)+ ']/div[2]').text    \n",
    "            Rank = browser.find_element(By.XPATH,'//*[@id=\"profile-scored-estimates\"]/div[1]/div[2]/a[' +\n",
    "                                                        str(j) + ']/div[4]').text \n",
    "            EPS_Points = browser.find_element(By.XPATH,'//*[@id=\"profile-scored-estimates\"]/div[1]/div[2]/a[' +\n",
    "                                                       str(j) + ']/div[5]').text\n",
    "            Revenue_Points = browser.find_element(By.XPATH,'//*[@id=\"profile-scored-estimates\"]/div[1]/div[2]/a['+\n",
    "                                                       str(j) + ']/div[6]').text\n",
    "            Total_Points = browser.find_element(By.XPATH,'//*[@id=\"profile-scored-estimates\"]/div[1]/div[2]/a['+\n",
    "                                                       str(j) + ']/div[7]').text\n",
    "                \n",
    "            insert_row.extend([analyst_list_2[i],ticker, Quarter, Rank, EPS_Points,\n",
    "                              Revenue_Points,Total_Points])\n",
    "            scored_list.append(insert_row)\n",
    "    \n",
    "pd.DataFrame(scored_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "dcdc5788",
   "metadata": {},
   "outputs": [],
   "source": [
    "scored.to_csv('last_table.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ecf5722fdaf1897a315d257d89d94520bfcaa453217d5becf09b39e73618b0de"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
